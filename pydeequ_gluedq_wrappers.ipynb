{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQDL Wrappers for PyDeequ\n",
    "\n",
    "This notebook expands upon the [basic_example](basic_example.ipynb) to define a Class having a set of 'quality' methods similar to the boto3 Glue.Class.   This provides a custom implementation of DLDQ-like functionality with alternate data stores in DynamoDb and S3, while supporting easy future migration to Glue ETL.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Scripts\n",
    "First execute Initialization and Definition cells below (these will eventually move to common library sourced here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Generate Rule Recommendations\n",
    "\n",
    "Rule recommendations utilize [Deequ *constraint suggestion*](https://github.com/awslabs/deequ/blob/master/src/main/scala/com/amazon/deequ/examples/constraint_suggestion_example.md) functionality to first profile all columns in the data set, and then apply heuristic rules to define a set of suggested constraints.\n",
    "\n",
    "This library adds a [DQDL-like Rule](https://docs.aws.amazon.com/glue/latest/dg/dqdl.html) to each suggested constraint, and stores the suggested constraints in **dqsuggestion_runs** DynamoDB table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataSource from S3 Url 's3a://wc2h-dtl-prd-datalake/PARQUET/tstg_creditor_agency/Unload.D230831/'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 152:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/09/12 13:30:40 WARN DAGScheduler: Broadcasting large task binary with size 1259.4 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'RunId': 'dqrecrun-2023-09-12T13:30:38.314605Z-interactive'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Generate Rule Recommendations\n",
    "s3_url = \"s3a://wc2h-dtl-prd-datalake/PARQUET/tstg_creditor_agency/Unload.D230831/\" # OK\n",
    "#s3_url = \"s3a://wc2h-dtl-prd-datalake/PARQUET/xstg_arclient/Unload.D230831/\" # too many cols\n",
    "#s3_url = \"s3a://wc2h-dtl-prd-datalake/PARQUET/xstg_arphone/Unload.D230831/\"  # wtf?\n",
    "\n",
    "arg = {\n",
    "    \"DataSource\" : {\n",
    "        \"S3Url\" : s3_url\n",
    "    }\n",
    "}\n",
    "\n",
    "dq = SimpleDQ()\n",
    "\n",
    "run_id = dq.start_data_quality_rule_recommendation_run( **arg )\n",
    "run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1a. Create Data Quality Ruleset from Recommendations\n",
    "Suggested Constraints provide a lot of detailed information about every column in the dataset. This library supports storing DQDL-like rules in a more concise format similar to Glue Data Quality API.  Rulesets stored in **dqrulesets** DynamoDB table can be edited to use only desired constraints, or to modify conditions applied (Hint -- use DynamoDB Form mode to edit the Ruleset string).  Alternatively, Rulesets can be defined from scratch.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RunId': 'dqrecrun-2023-09-12T13:30:38.314605Z-interactive'}\n",
      "Getting Suggestion Run dqrecrun-2023-09-12T13:30:38.314605Z-interactive\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Name': 'tstg_creditor_agency_generated'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### 1a. Convert Recommendations to a Ruleset\n",
    "\n",
    "print(run_id) # from Step 1\n",
    "\n",
    "tablename = get_tablename_from_datasource( arg['DataSource'] ) # from Step 1\n",
    "\n",
    "dq = SimpleDQ()\n",
    "\n",
    "rec = dq.get_data_quality_rule_recommendation_run( **run_id )\n",
    "rec\n",
    "rules_list = []\n",
    "for item in rec['ConstraintSuggestions']:\n",
    "    rules_list.append( item['dqdl_rule'] )\n",
    "    \n",
    "#print(rules_list)\n",
    "\n",
    "ruleset = {\n",
    " \"Name\": f\"{tablename}_generated\",\n",
    " \"ClientToken\": \"string\",\n",
    " \"Description\": \"ruleset from pydeequ.suggestions\",\n",
    " \"Ruleset\": \", \\n\".join(rules_list) , # stored as string\n",
    " \"Tags\": {\n",
    "  \"SuggestionRunId\": rec[\"RunId\"]\n",
    " },\n",
    " \"DataSource\" : rec[\"DataSource\"],    # custom  \n",
    " \"TargetTable\": {\n",
    "  \"CatalogId\": \"AwsDataCatalog\",\n",
    "  \"DatabaseName\": \"dtl-prd-smpl0-g2\", # ToDo from variable\n",
    "  \"TableName\": tablename\n",
    " }\n",
    "}\n",
    "\n",
    "dq.update_data_quality_ruleset(**ruleset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Run Ruleset to Evaluate Data Quality\n",
    "Next, the Ruleset can be evaluated against particular data sets to verify compliance with each of the constraints.   Ruleset Evaluation Runs are logged in **dqruleset-eval-runs** DynamoDB table, which associates the evaluated Datasource with Rulesets applied and the Results of the evaluation.   Multiple Rulesets can be applied against a DataSource in the same Evaluation Run, to generate multiple Results stored in **dqresults** table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Ruleset tstg_creditor_agency_generated\n",
      "DataSource from S3 Url 's3a://wc2h-dtl-prd-datalake/PARQUET/tstg_creditor_agency/Unload.D230831/'\n",
      "Getting Ruleset tstg_creditor_agency_generated\n",
      "Skipping Check -- Rule Type 'HasDataType' is not implemented.\n",
      "Skipping Check -- Rule Type 'HasCompleteness' is not implemented.\n",
      "{'RULES': 80, 'PASS': 64, 'FAIL': 14, 'SKIP': 2}\n",
      "Getting Eval Run dqrun-2023-09-12T13:37:59.031230Z-interactive\n",
      "Getting Result dqresult-2023-09-12T13:37:59.262032Z-tstg_creditor_agency_generated\n",
      "Score: 0.8205128205128205\n",
      "Tally: {'SKIP': Decimal('2'), 'RULES': Decimal('80'), 'PASS': Decimal('64'), 'FAIL': Decimal('14')}\n"
     ]
    }
   ],
   "source": [
    "#### 2. Run Ruleset to Evaluate Data Quality\n",
    "\n",
    "dq = SimpleDQ()\n",
    "\n",
    "ruleset_name = f\"{tablename}_generated\"  # from Step 1a\n",
    "\n",
    "ruleset = dq.get_data_quality_ruleset( Name = ruleset_name )\n",
    "#print(ruleset)\n",
    "\n",
    "# note the option to evaluate multiple Rulesets by name in same run\n",
    "ruleset_runspec = {\n",
    "    'DataSource': ruleset['DataSource'],\n",
    "    'RulesetNames' : [\n",
    "        ruleset['Name'],\n",
    "    ]\n",
    "}\n",
    "\n",
    "eval_run_id = dq.start_data_quality_ruleset_evaluation_run( **ruleset_runspec)\n",
    "\n",
    "dq_eval_run = dq.get_data_quality_ruleset_evaluation_run( **eval_run_id )\n",
    "\n",
    "# note that a ResultId will be generated for each Ruleset\n",
    "for result_id in dq_eval_run['ResultIds']:\n",
    "    dq_result = dq.get_data_quality_result( ResultId = result_id )\n",
    "\n",
    "#print(json.dumps(dq_result, default=str, indent=2))\n",
    "print( f\"Score: {dq_result['Score']}\")\n",
    "#print( f\"Tally: {dq_result['Tally']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# cold start\n",
    "pip install pydeequ\n",
    "pip install 'awswrangler[redshift]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# cold start for SageMaker on WC2H -- unzip dependencies from local file, since Maven is blocked\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "S_rootdir = os.getcwd()\n",
    "\n",
    "with zipfile.ZipFile( f\"{S_rootdir}/common/ivy2cache.zip\" ) as z:\n",
    "    z.extractall( f\"{os.environ['HOME']}/.ivy2\" )\n",
    "\n",
    "with zipfile.ZipFile( f\"{S_rootdir}/common/ivy2cache_33.zip\" ) as z:\n",
    "    z.extractall( f\"{os.environ['HOME']}/.ivy2\" )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['AWS_DEFAULT_REGION'] = 'us-gov-west-1'\n",
    "#os.environ[\"SPARK_VERSION\"] = '3.0'\n",
    "os.environ[\"SPARK_VERSION\"] = '3.3'\n",
    "\n",
    "import awswrangler as wr\n",
    "import pandas as pd\n",
    "pd.DataFrame.iteritems = pd.DataFrame.items # (https://stackoverflow.com/questions/75926636/databricks-issue-while-creating-spark-data-frame-from-pandas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring non-Spark config property: fs.s3a.endpoint\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pyspark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/ec2-user/.ivy2/cache\n",
      "The jars for the packages stored in: /home/ec2-user/.ivy2/jars\n",
      "com.amazon.deequ#deequ added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-7a85ebe5-2cb1-49a8-b364-74064c0b02af;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.amazon.deequ#deequ;2.0.3-spark-3.3 in central\n",
      "\tfound org.scala-lang#scala-reflect;2.12.10 in central\n",
      "\tfound org.scalanlp#breeze_2.12;0.13.2 in central\n",
      "\tfound org.scalanlp#breeze-macros_2.12;0.13.2 in central\n",
      "\tfound com.github.fommil.netlib#core;1.1.2 in central\n",
      "\tfound net.sf.opencsv#opencsv;2.3 in central\n",
      "\tfound com.github.rwl#jtransforms;2.4.0 in central\n",
      "\tfound junit#junit;4.8.2 in central\n",
      "\tfound org.apache.commons#commons-math3;3.2 in central\n",
      "\tfound org.spire-math#spire_2.12;0.13.0 in central\n",
      "\tfound org.spire-math#spire-macros_2.12;0.13.0 in central\n",
      "\tfound org.typelevel#machinist_2.12;0.6.1 in central\n",
      "\tfound com.chuusai#shapeless_2.12;2.3.2 in central\n",
      "\tfound org.typelevel#macro-compat_2.12;1.1.1 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.5 in central\n",
      ":: resolution report :: resolve 353ms :: artifacts dl 15ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazon.deequ#deequ;2.0.3-spark-3.3 from central in [default]\n",
      "\tcom.chuusai#shapeless_2.12;2.3.2 from central in [default]\n",
      "\tcom.github.fommil.netlib#core;1.1.2 from central in [default]\n",
      "\tcom.github.rwl#jtransforms;2.4.0 from central in [default]\n",
      "\tjunit#junit;4.8.2 from central in [default]\n",
      "\tnet.sf.opencsv#opencsv;2.3 from central in [default]\n",
      "\torg.apache.commons#commons-math3;3.2 from central in [default]\n",
      "\torg.scala-lang#scala-reflect;2.12.10 from central in [default]\n",
      "\torg.scalanlp#breeze-macros_2.12;0.13.2 from central in [default]\n",
      "\torg.scalanlp#breeze_2.12;0.13.2 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.5 from central in [default]\n",
      "\torg.spire-math#spire-macros_2.12;0.13.0 from central in [default]\n",
      "\torg.spire-math#spire_2.12;0.13.0 from central in [default]\n",
      "\torg.typelevel#machinist_2.12;0.6.1 from central in [default]\n",
      "\torg.typelevel#macro-compat_2.12;1.1.1 from central in [default]\n",
      "\t:: evicted modules:\n",
      "\torg.scala-lang#scala-reflect;2.12.1 by [org.scala-lang#scala-reflect;2.12.10] in [default]\n",
      "\torg.scala-lang#scala-reflect;2.12.0 by [org.scala-lang#scala-reflect;2.12.10] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   17  |   0   |   0   |   2   ||   15  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-7a85ebe5-2cb1-49a8-b364-74064c0b02af\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 15 already retrieved (0kB/9ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/09/11 20:24:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/09/11 20:24:53 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "23/09/11 20:24:53 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession, Row, DataFrame\n",
    "\n",
    "import sagemaker_pyspark\n",
    "import pydeequ\n",
    "\n",
    "classpath = \":\".join(sagemaker_pyspark.classpath_jars())\n",
    "\n",
    "from pyspark import SparkConf\n",
    "conf = (SparkConf()\n",
    "        .set('fs.s3a.endpoint', 's3-us-gov-west-1.amazonaws.com')\n",
    "        .set(\"spark.sql.parquet.int96RebaseModeInRead\", \"CORRECTED\")\n",
    "        .set(\"spark.sql.parquet.int96RebaseModeInWrite\", \"CORRECTED\")\n",
    "        .set(\"spark.sql.parquet.datetimeRebaseModeInRead\", \"CORRECTED\")\n",
    "        .set(\"spark.sql.parquet.datetimeRebaseModeInWrite\", \"CORRECTED\")        \n",
    "       )\n",
    "\n",
    "spark = (SparkSession\n",
    "    .builder\n",
    "    .config(\"spark.driver.extraClassPath\", classpath)\n",
    "    .config(\"spark.jars.packages\", pydeequ.deequ_maven_coord)\n",
    "    .config(\"spark.jars.excludes\", pydeequ.f2j_maven_coord)\n",
    "    .config( conf=conf )\n",
    "    .getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function and Class Definitions\n",
    "Will be moved to common module for access from either notebook or ETL jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def parse_dqdl_rule(rule_text): # ToDo move to common module\n",
    "    \"\"\" Transform a DQDL-like rule from string to dict \"\"\"\n",
    "    import json\n",
    "    import re\n",
    "    \n",
    "    s = rule_text.split(' ', 2)\n",
    "\n",
    "    rule = {\n",
    "        'Type' : s[0],\n",
    "        'ColName' : '',\n",
    "        'Expression' : '',\n",
    "        'Lambda' : None,\n",
    "        'Text' : rule_text\n",
    "    }\n",
    "    if '\"' in s[1]:\n",
    "        rule['ColName'] = s[1].replace('\"','')\n",
    "        if len(s) == 3:\n",
    "            rule['Expression'] = s[2]\n",
    "    else:\n",
    "        rule['Expression'] = f\"{s[1]} {s[2]}\"\n",
    "\n",
    "    # transform the Expression into a lambda assertion\n",
    "    if rule['Expression'] == '':\n",
    "        pass\n",
    "    \n",
    "    elif re.search(\"[<=>]\", rule['Expression']):\n",
    "        xpr = rule['Expression'].split()\n",
    "        op =  xpr[0]\n",
    "        val = float(xpr[1])\n",
    "        if op == \"=\":\n",
    "            rule['Lambda'] = lambda x: x == val\n",
    "        elif op == \">\":\n",
    "            rule['Lambda'] = lambda x: x > val\n",
    "        elif op == \"<\":\n",
    "            rule['Lambda'] = lambda x: x < val\n",
    "        elif op == \">=\":\n",
    "            rule['Lambda'] = lambda x: x >= val\n",
    "        elif op == \"<=\":\n",
    "            rule['Lambda'] = lambda x: x <= val\n",
    "        \n",
    "    elif rule['Expression'].startswith('between'):\n",
    "        xpr = rule['Expression'].split()\n",
    "        lo = xpr[1]\n",
    "        hi = xpr[3]\n",
    "        rule['Lambda'] = lambda x: lo < x < hi\n",
    "        \n",
    "    elif rule['Expression'].startswith('in'): \n",
    "        xpr = rule['Expression'].split() # no spaces between list values, please!\n",
    "        inlist = xpr[1][1:-1].replace('\"','').split(',')\n",
    "        #rule['Lambda'] = lambda x: x in inlist\n",
    "        rule['Lambda'] = inlist\n",
    "        \n",
    "    else:\n",
    "        print(\"Can't Parse Expression\")\n",
    "    \n",
    "    #print(json.dumps(rule, indent=2, default=str))\n",
    "\n",
    "    return rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#def run_pydeequ_checks( df, ruleset_name ): # ToDo move to common module\n",
    "def run_pydeequ_checks( df, ruleset_name, rules_list ): # ToDo move to common module\n",
    "    from pydeequ.checks import Check,CheckLevel\n",
    "    from pydeequ.verification import VerificationSuite,VerificationResult\n",
    "    import datetime\n",
    "    beg_time = datetime.datetime.now().strftime(\"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "    dq_result_id = f'dqresult-{beg_time}-{ruleset_name}'\n",
    "    \n",
    "    # create check object representing a set of constraints \n",
    "    check = Check(spark, CheckLevel.Error, ruleset_name)\n",
    "    \n",
    "    parsed_rules = []\n",
    "    for rule_text in rules_list:\n",
    "        rule = parse_dqdl_rule(rule_text)\n",
    "        rule['status'] = 'processed'\n",
    "\n",
    "        if rule['Type'] == 'HasSize':\n",
    "            check.hasSize( rule['Lambda'] )\n",
    "        elif rule['Type'] == 'HasMin':\n",
    "            check.hasMin( rule['ColName'], rule['Lambda'] )\n",
    "        elif rule['Type'] == 'IsComplete':\n",
    "            check.isComplete( rule['ColName'] )        \n",
    "        elif rule['Type'] == 'IsUnique':\n",
    "            check.isUnique( rule['ColName'] )        \n",
    "        elif rule['Type'] == 'IsContainedIn':  \n",
    "            check.isContainedIn(rule['ColName'], rule['Lambda'])\n",
    "        elif rule['Type'] == 'IsNonNegative':\n",
    "            check.isNonNegative( rule['ColName'] )\n",
    "        else:\n",
    "            rule['status'] = 'skipped'\n",
    "            msg = f\"Skipping Check -- Rule Type '{rule['Type']}' is not implemented.\"\n",
    "            '''\n",
    "            skipped.append( {\n",
    "                'constraint' : rule_text,\n",
    "                'constraint_status' : 'Skipped',\n",
    "                'constraint_message' : msg\n",
    "            })'''\n",
    "            print( msg )\n",
    "        parsed_rules.append( rule )\n",
    "\n",
    "    # apply constraints to data frame\n",
    "    checkResult = VerificationSuite(spark).onData(df).addCheck(check).run()\n",
    "\n",
    "    # get DeeQu results and customize to resemble Glue Data Quality API\n",
    "    check_results = checkResult.checkResults # dict\n",
    "    j=-1\n",
    "    rule_results = []\n",
    "\n",
    "    for i in range(len(parsed_rules)):\n",
    "        #print(i,j)\n",
    "        rule_result = {\n",
    "            \"Name\" : f\"Rule_{i}\",\n",
    "            \"Description\" : parsed_rules[i][\"Text\"]\n",
    "        }\n",
    "        if parsed_rules[i]['status'] == 'processed':\n",
    "            j += 1\n",
    "            rule_result.update ( {\n",
    "                \"EvaluationMessage\" : check_results[j][\"constraint_message\"],\n",
    "                \"EvaluatedMetrics\" : {\n",
    "                    \"Constraint\" : check_results[j][\"constraint\"]\n",
    "                }                        \n",
    "            } )\n",
    "            if check_results[j]['constraint_status'] == 'Success':\n",
    "                rule_result['Result'] = 'PASS'\n",
    "            elif check_results[j]['constraint_status'] == 'Failure':\n",
    "                rule_result['Result'] = 'FAIL'\n",
    "            else:\n",
    "                rule_result['Result'] = 'ERROR'\n",
    "            \n",
    "        elif parsed_rules[i]['status'] == 'skipped':\n",
    "            rule_result['Result'] = 'SKIP'\n",
    "            rule_result.update ( {\n",
    "                \"EvaluationMessage\" : f\"Rule Type '{parsed_rules[i]['Type']}' is not implemented.\",\n",
    "                \"EvaluatedMetrics\" : {},\n",
    "                \"Result\" : rule_result['Result']\n",
    "            } )   \n",
    "            \n",
    "        rule_results.append( rule_result )\n",
    "\n",
    "        end_time = datetime.datetime.now().strftime(\"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "\n",
    "    df_dq_result = pd.DataFrame.from_dict(rule_results, orient='columns')\n",
    "    \n",
    "    tally = { \n",
    "        'RULES' : len(df_dq_result),\n",
    "        'PASS' : 0,\n",
    "        'FAIL' : 0 }\n",
    "    ls = list(df_dq_result['Result'])\n",
    "    x = set(ls)\n",
    "    for item in x:\n",
    "        tally.update( {item : ls.count(item)} )\n",
    "\n",
    "    print(tally)\n",
    "    score = tally['PASS'] / ( tally['PASS'] + tally['FAIL'] )\n",
    "    #tally, score\n",
    "\n",
    "    result = {\n",
    "        \"ResultId\" : dq_result_id,\n",
    "        \"Score\" : score ,\n",
    "        \"Tally\" : tally ,\n",
    "        \"DataSource\" : \"DataFrame\",\n",
    "        \"RulesetName\" : ruleset_name,\n",
    "        \"StartedOn\" : beg_time,\n",
    "        \"CompletedOn\" : end_time,\n",
    "        \"RulesetEvaluationRunId\": \"unknown\",\n",
    "        \"RuleResults\": rule_results\n",
    "    }\n",
    "\n",
    "    return result # dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_dataframe_from_datasource( DataSource ):\n",
    "    \n",
    "    # Three options for DataSource ...\n",
    "    if 'GlueTable' in DataSource.keys(): # GlueDQ (like Glue Data Quality API)\n",
    "        table = DataSource['GlueTable']\n",
    "        s3_url = wr.catalog.get_table_location( database=table['DatabaseName'], table=table['TableName'])\n",
    "        s3_url = s3_url + '/*/*'\n",
    "        print (f\"DataSource from GlueTable '{table['DatabaseName']}.{table['TableName']}'\")\n",
    "\n",
    "    elif 'S3Url' in DataSource.keys():   # DataSource Alt #1 (custom)\n",
    "        s3_url = DataSource['S3Url']\n",
    "        # table = DataSource['TableName'] # ToDo substring of S3Url\n",
    "        print (f\"DataSource from S3 Url '{s3_url}'\")\n",
    "    '''    \n",
    "    elif 'SQL' in DataSource.keys():  # ToDo DataSource Alt #2 (custom)  \n",
    "        s3_url = None\n",
    "        sql = DataSource['Athena']['SQL']\n",
    "        dbname = DataSource['Athena']['DataBase']\n",
    "        \n",
    "        # ToDo read Athena and/or Redshift (Spectrum) into Spark df\n",
    "        df_pd = wr.athena.read_sql_query(sql, database=dbname)\n",
    "        print('Convert Pandas to Spark')\n",
    "        df = spark.createDataFrame(df_pd) \n",
    "    '''    \n",
    "    if s3_url:\n",
    "        df = spark.read.parquet( s3_url.replace( 's3://', 's3a://') )\n",
    "        \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tablename_from_datasource( DataSource ):\n",
    "    if 'GlueTable' in DataSource.keys(): # GlueDQ (like Glue Data Quality API)\n",
    "        tablename = DataSource['GlueTable']['TableName']\n",
    "\n",
    "    elif 'S3Url' in DataSource.keys():   # DataSource Alt #1 (custom)\n",
    "        s3_url = DataSource['S3Url']\n",
    "        tablename = s3_url.split('/')[4] # ToDo improve\n",
    "    '''    \n",
    "    elif 'SQL' in DataSource.keys():  # ToDo DataSource Alt #2 (custom)  \n",
    "    '''    \n",
    "    return tablename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pydeequ_suggestions( df ): # ToDo move to common module\n",
    "    from pydeequ.suggestions import ConstraintSuggestionRunner, DEFAULT\n",
    "\n",
    "    constraint_suggestions = ConstraintSuggestionRunner(spark) \\\n",
    "             .onData(df) \\\n",
    "             .addConstraintRule(DEFAULT()) \\\n",
    "             .run()\n",
    "    \n",
    "    # transform pydeequ code into DQDL rule \n",
    "    for item in constraint_suggestions[\"constraint_suggestions\"]:\n",
    "        x = item[\"code_for_constraint\"]\n",
    "        if item['suggesting_rule'].startswith('FractionalCategoricalRangeRule'):\n",
    "            x = x[:x.find(', lambda')]\n",
    "        elif item['suggesting_rule'].startswith('RetainCompletenessRule'):\n",
    "            y = x.split(', ')\n",
    "            x = f\"{y[0]} {y[1].replace('lambda x: x ','')}\"            \n",
    "        for y in re.findall('\\[.*?\\]', x): \n",
    "            x = x.replace( y, y.replace(', ', ','))\n",
    "        x = re.sub(r'[()]', ' ', (x[1].upper() + x[2:])).replace( ', ', ' in ').strip() \n",
    "        item.update( {\n",
    "            'dqdl_rule' : x\n",
    "        })\n",
    "\n",
    "    return constraint_suggestions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import re\n",
    "\n",
    "class SimpleDQ: # ToDo move to common module\n",
    "    ''' Data Quality functionality similar to boto3 Glue.Client '''\n",
    "    import datetime\n",
    "\n",
    "    import boto3\n",
    "    glue_client = boto3.client('glue')\n",
    "    ddb_resource = boto3.resource('dynamodb')\n",
    "    \n",
    "    # DynamoDb Tables for PyDeeQu data stores similar to Glue Data Quality API\n",
    "    dqrulesets_table = ddb_resource.Table('dtl-prd-SMPL0-dqrulesets') \n",
    "    dqruleset_eval_runs_table = ddb_resource.Table('dtl-prd-SMPL0-dqruleset-eval-runs') \n",
    "    dqresults_table = ddb_resource.Table('dtl-prd-SMPL0-dqresults') \n",
    "    dqsuggestion_runs_table = ddb_resource.Table('dtl-prd-SMPL0-dqsuggestion_runs') \n",
    "    #dqsuggestions_table = ddb_resource.Table('dtl-prd-SMPL0-dqsuggestions') \n",
    "    \n",
    "    mode='PyDeeQu'  \n",
    "\n",
    "    def __init__(self, mode='PyDeeQu', **kwargs) -> None:\n",
    "        if mode == 'GlueDQ':\n",
    "            # pass-thru wrapper for boto3 class Glue.Client *data_quality* methods\n",
    "            print('Glue Data Quality implementation pending availability on Govcloud')\n",
    "        self.mode = mode\n",
    "\n",
    "    def batch_get_data_quality_result(self, **kwargs): pass # ToDo \n",
    "    def cancel_data_quality_rule_recommendation_run(self, **kwargs): pass # ToDo \n",
    "    def cancel_data_quality_ruleset_evaluation_run(self, **kwargs): pass # ToDo\n",
    "\n",
    "    def create_data_quality_ruleset( self, **kwargs):\n",
    "        if type(kwargs['Ruleset']) == list:\n",
    "            \", \".join(kwargs['Ruleset'])\n",
    "\n",
    "        if self.mode == \"GlueDQ\":\n",
    "            response = self.glue_client.create_data_quality_ruleset(\n",
    "                Name = kwargs['Name'],       # str Reqd\n",
    "                Ruleset = kwargs['Ruleset'], # str Reqd \n",
    "                Description = kwargs['Description'],\n",
    "                Tags = kwargs['Tags'],      # dict\n",
    "                TargetTable = kwargs['TargetTable'], # dict\n",
    "                ClientToken = kwargs['ClientTokens']\n",
    "            )\n",
    "            return response   # { 'Name': 'string' }\n",
    "        elif self.mode == \"PyDeeQu\":\n",
    "            now = datetime.datetime.now().strftime(\"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "            kwargs.update( {\n",
    "                'CreatedOn' : now,\n",
    "                'LastModifiedOn' : now\n",
    "            })\n",
    "            self.dqrulesets_table.put_item(\n",
    "                Item = kwargs\n",
    "            )\n",
    "            return { 'Name' : kwargs['Name'] }\n",
    "\n",
    "    def delete_data_quality_ruleset(self, **kwargs): pass # ToDo\n",
    "\n",
    "    def get_data_quality_result(self, **kwargs): \n",
    "        print(f\"Getting Result {kwargs['ResultId']}\")\n",
    "        response = self.dqresults_table.get_item(\n",
    "            Key = { 'ResultId' : kwargs['ResultId'] }\n",
    "        )\n",
    "        return response['Item']\n",
    "    \n",
    "    def get_data_quality_rule_recommendation_run(self, **kwargs): \n",
    "        print(f\"Getting Suggestion Run {kwargs['RunId']}\")\n",
    "        response = self.dqsuggestion_runs_table.get_item(\n",
    "            Key = { 'RunId' : kwargs['RunId'] }\n",
    "        )\n",
    "        return response['Item']\n",
    "\n",
    "    def get_data_quality_ruleset(self, **kwargs): \n",
    "        print(f\"Getting Ruleset {kwargs['Name']}\")\n",
    "        if self.mode == \"GlueDQ\":\n",
    "            print('Glue Data Quality implementation pending availability on Govcloud')\n",
    "            '''response = self.glue_client.get_data_quality_ruleset(\n",
    "                Name=kwargs['Name']\n",
    "            )\n",
    "            return response'''\n",
    "        elif self.mode == \"PyDeeQu\":\n",
    "            response = self.dqrulesets_table.get_item(\n",
    "                Key = { 'Name' : kwargs['Name'] }\n",
    "            )\n",
    "            return response['Item']\n",
    "       \n",
    "    def get_data_quality_ruleset_evaluation_run(self, **kwargs): \n",
    "        print(f\"Getting Eval Run {kwargs['RunId']}\")\n",
    "        if self.mode == \"GlueDQ\":\n",
    "            print('Glue Data Quality implementation pending availability on Govcloud')\n",
    "\n",
    "        elif self.mode == \"PyDeeQu\":\n",
    "            response = self.dqruleset_eval_runs_table.get_item(\n",
    "                Key = { 'RunId' : kwargs['RunId'] }\n",
    "            )\n",
    "            return response['Item']\n",
    "    \n",
    "    def list_data_quality_results(self, **kwargs): pass # ToDo\n",
    "    def list_data_quality_rule_recommendation_runs(self, **kwargs): pass # ToDo\n",
    "    def list_data_quality_ruleset_evaluation_runs(self, **kwargs): pass # ToDo\n",
    "    def list_data_quality_rulesets(self, **kwargs): pass # ToDo\n",
    "    \n",
    "    def start_data_quality_rule_recommendation_run(self, **kwargs):\n",
    "        if self.mode == \"GlueDQ\":\n",
    "            print('Glue Data Quality implementation pending availability on Govcloud')\n",
    "\n",
    "        elif self.mode == \"PyDeeQu\":\n",
    "            # 'lightweight' interactive option for logic that will be implemented in Glue ETL job\n",
    "            beg_time = datetime.datetime.now().strftime(\"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "            dqrunid = f'dqrecrun-{beg_time}-interactive'\n",
    "            \n",
    "            process_parms = kwargs            \n",
    "            process_parms.update ({\n",
    "                'RunId' : dqrunid,\n",
    "                'Status' : 'RUNNING',\n",
    "                'StartedOn' : beg_time\n",
    "            })\n",
    "            # Store in DynDb table\n",
    "            self.dqsuggestion_runs_table.put_item( Item = process_parms )\n",
    "            \n",
    "            df = get_dataframe_from_datasource( process_parms['DataSource'] )\n",
    "\n",
    "            dq_suggestions = run_pydeequ_suggestions( df )\n",
    "\n",
    "            process_parms.update ({\n",
    "                'ConstraintSuggestions' : dq_suggestions['constraint_suggestions'], \n",
    "                'Status' : 'SUCCEEDED',\n",
    "                'CompletedOn' : datetime.datetime.now().strftime(\"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "            })\n",
    "            # Store in DynDb table\n",
    "            self.dqsuggestion_runs_table.put_item( Item = process_parms )\n",
    "            \n",
    "            return { 'RunId': process_parms['RunId'] }\n",
    "    \n",
    "    def start_data_quality_ruleset_evaluation_run(self, **kwargs): \n",
    "        import datetime\n",
    "\n",
    "        if self.mode == \"GlueDQ\":\n",
    "            print('Glue Data Quality implementation pending availability on Govcloud')\n",
    "\n",
    "        elif self.mode == \"PyDeeQu\":\n",
    "\n",
    "            # 'lightweight' interactive option for logic that will be implemented in Glue ETL job\n",
    "            beg_time = datetime.datetime.now().strftime(\"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "            dqrunid = f'dqrun-{beg_time}-interactive'\n",
    "            \n",
    "            process_parms = kwargs\n",
    "            process_parms.update ({\n",
    "                'RunId' : dqrunid,\n",
    "                'ResultIds' : [],\n",
    "                'Status' : 'RUNNING',\n",
    "                'StartedOn' : beg_time\n",
    "            })\n",
    "            \n",
    "            # Store in DynDb table\n",
    "            self.dqruleset_eval_runs_table.put_item( Item = process_parms )\n",
    "            \n",
    "            df = get_dataframe_from_datasource( process_parms['DataSource'] )\n",
    "                \n",
    "            for ruleset_name in process_parms['RulesetNames']:\n",
    "                ruleset = self.get_data_quality_ruleset( Name = ruleset_name ) \n",
    "                rules_list = ruleset['Ruleset'].replace('\\n','').split(', ')\n",
    "                \n",
    "                dq_result = run_pydeequ_checks( df, ruleset_name, rules_list ) \n",
    "                dq_result.update( {\n",
    "                    'DataSource' : process_parms['DataSource'],\n",
    "                    'RulesetEvaluationRunId' : process_parms['RunId']\n",
    "                })\n",
    "                \n",
    "                import json\n",
    "                from decimal import Decimal\n",
    "                dq_result = json.loads(json.dumps(dq_result), parse_float=Decimal)\n",
    "                self.dqresults_table.put_item(\n",
    "                    Item = dq_result\n",
    "                )\n",
    "                                \n",
    "                process_parms['ResultIds'].append( dq_result['ResultId'] )\n",
    "            \n",
    "            process_parms.update ({\n",
    "                'Status' : 'SUCCEEDED',\n",
    "                'CompletedOn' : datetime.datetime.now().strftime(\"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "            })\n",
    "\n",
    "            # Store in DynDb table\n",
    "            self.dqruleset_eval_runs_table.put_item( Item = process_parms )\n",
    "            \n",
    "            return { 'RunId': process_parms['RunId'] }\n",
    "    \n",
    "    def update_data_quality_ruleset(self, **kwargs): \n",
    "        if self.mode == \"GlueDQ\":\n",
    "            response = self.glue_client.update_data_quality_ruleset(\n",
    "                Name = kwargs['Name'],\n",
    "                Description = kwargs['Description'],\n",
    "                Ruleset = kwargs['Ruleset']\n",
    "            )\n",
    "            return response\n",
    "        elif self.mode == \"PyDeeQu\":\n",
    "            # 'put_item' works for both create and update\n",
    "            now = datetime.datetime.now().strftime(\"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "\n",
    "            kwargs.update( {\n",
    "                'LastModifiedOn' : now\n",
    "            })\n",
    "            self.dqrulesets_table.put_item(\n",
    "                Item = kwargs\n",
    "            )\n",
    "            return { 'Name' : kwargs['Name'] }\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
